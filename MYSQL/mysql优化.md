


# 8. SQL 优化
## 如何定位及优化SQL语句的性能问题？
对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了EXPLAIN命令来查看语句的执行计划。
- id

执行计划包含的信息 id 有一组数字组成。表示一个查询中各个子查询的执行顺序;        
id相同执行顺序由上至下。        
id不同，id值越大优先级越高，越先被执行。        
id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。        

- select_type
每个子查询的查询类型，一些常见的查询类型如下:  
SIMPLE	不包含任何子查询或union等查询  
PRIMARY	包含子查询最外层查询就显示为 PRIMARY  
SUBQUERY	在select或 where字句中包含的查询  
DERIVED	from字句中包含的查询  
UNION	出现在union后的查询语句中  
UNION RESULT	从UNION中获取结果集，例如上文的第三个例子  

- table
查询的数据表，当从衍生表中查数据时会显示 x 表示对应的执行计划id partitions 表分区、表创建的时候可以指定通过那个列进行表分区。 

- type(非常重要)

可以看到有没有走索引
ALL 扫描全表数据  
index 遍历索引  
range 索引范围查找  
index_subquery 在子查询中使用 ref  
unique_subquery 在子查询中使用 eq_ref  
ref_or_null 对Null进行索引的优化的 ref  
fulltext 使用全文索引   
ref 使用非唯一索引查找数据   
eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。   

- possible_keys 可能使用的索引，注意不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为 NULL时就要考虑当前的SQL是否需要优化了。  

- key
显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。

- TIPS:
查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中

- key_length
索引长度

- ref
表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

- rows
返回估算的结果集数目，并不是一个准确的值。

- extra
常见信息如下  
Using index 使用覆盖索引   
Using where 使用了用where子句来过滤结果集   
Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。   
Using temporary 使用了临时表 sql优化的目标可以参考阿里开发手册   

SQL性能优化的目标：  
type类型，至少要达到 range 级别，要求是ref级别，如果可以是consts最好。  

consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。  
ref 指的是使用普通的索引（normal index）。  
range 对索引进行范围检索。  
反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫。  

## 大表数据查询，怎么优化？
优化shema、sql语句+索引；  
第二加缓存，memcached, redis；  
主从复制，读写分离；  
垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；  
水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；  

## MySQL 数据库服务器性能分析的方法命令有哪些?


## MySQL 分页如何优化？
LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1)  

```
-- 检索记录行 6-15
SELECT * FROM table LIMIT 5,10;  
```
为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：        

如果只给定一个参数，它表示返回最大的记录行数目：  

超大分页怎么优化？超大的分页一般从两个方向上来解决.   
- 数据库层面,
也是我们主要集中关注的(虽然收效没那么大),类似于  
select * from table where age > 20 limit 1000000,10;  
这种查询其实也是有可以优化的余地的. 这条语句需要加载1000000数据然后基本上全部丢弃,只取10条当然比较慢. 我们可以修改为  
select * from table where id in (select id from table where age > 20 limit 1000000,10)  
这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快.   

优化的可能性有许多种,但是核心思想都一样,就是减少加载的数据.  

- 从需求的角度减少这种请求
主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.
解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可.

## 如何使用慢查询日志？
慢查询日志用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。

- 开启慢查询日志

配置项：slow_query_log
查看：show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF
设置：set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。
- 设置临界时间

配置项：long_query_time
查看：show VARIABLES like 'long_query_time'，单位秒
设置：set long_query_time=0.5
实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉

- 查看日志
一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中

## 如何分析慢查询？对慢查询如何优化？
慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？

所以优化也是针对这三个方向来的，

- 首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。
- 分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。
- 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。

## 优化查询过程中的数据可以从那些点入手？
数据量，是否放我不必要数据，返回指定的列名，是否使用索引等
访问数据太多导致查询性能下降  
确定应用程序是否在检索大量超过需要的数据，可能是太多行或列  
确认MySQL服务器是否在分析大量不必要的数据行 
避免犯如下SQL语句错误  
查询不需要的数据。解决办法：使用limit解决 
多表关联返回全部列。解决办法：指定列名  
总是返回全部列。解决办法：避免使用SELECT *  
重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存  
是否在扫描额外的记录。
解决办法：
使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化：
使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。
改变数据库和表的结构，修改数据表范式
重写SQL语句，让优化器可以以更优的方式执行查询。


## count汇总该如何优化？
count(*)会忽略所有的列，直接统计所有列数，不要使用count(列名)
MyISAM中，没有任何where条件的count(*)非常快。
当有where条件时，MyISAM的count统计不一定比其它引擎快。
可以使用explain查询近似值，用近似值替代count(*)
增加汇总表
使用缓存

## 如何优化关联查询？
确定ON或者USING子句中是否有索引。
确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。

## 如何优化子查询？
用关联查询替代  
优化GROUP BY和DISTINCT  
这两种查询据可以使用索引来优化，是最有效的优化方法  
关联查询中，使用标识列分组的效率更高  
如果不需要ORDER BY，进行GROUP BY时加ORDER BY NULL，MySQL不会再进行文件排序。  
WITH ROLLUP超级聚合，可以挪到应用程序处理  

## 如何优化LIMIT分页？
LIMIT偏移量大的时候，查询效率较低
可以记录上次查询的最大ID，下次查询时直接根据该ID来查询

## 读写分离有哪些解决方案？
读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。

- 方案一
使用mysql-proxy代理

优点：
直接实现读写分离和负载均衡，不用修改代码，master和slave用一样的帐号，mysql官方不建议实际生产中使用
缺点：
降低性能， 不支持事务
- 方案二
使用AbstractRoutingDataSource + aop + annotation在dao层决定数据源。
如果采用了mybatis， 可以将读写分离放在ORM层，比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。 plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。

- 方案三
使用AbstractRoutingDataSource + aop + annotation在service层决定数据源，可以支持事务.

## 如何优化UNION查询？
UNION ALL的效率高于UNION


## 如何优化WHERE子句？
对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。  

应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描  

应尽量避免在 where 子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行全表扫描。  

应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：

in 和 not in 也要慎用，否则会导致全表扫描  

下面的查询也将导致全表扫描：select id from t where name like ‘%李%’若要提高效率，可以考虑全文检索。    

如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：

select id from t where num=@num
-- 可以改为强制查询使用索引：
select id from t with(index(索引名)) where num=@num

应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：

select id from t where num/2=100
-- 应改为:
select id from t where num=100*2


应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：

select id from t where substring(name,1,3)=’abc’
-- name以abc开头的id应改为:
select id from t where name like ‘abc%’



不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

9. 数据库优化
为什么要优化数据库？
系统的吞吐量瓶颈往往出现在数据库的访问速度上
随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢
数据是存放在磁盘上的，读写速度无法和内存相比
优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度。

数据库结构优化可以从那些方面入手？
一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。

需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。

将字段很多的表分解成多个表
对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。
因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。

增加中间表
对于需要经常联合查询的表，可以建立中间表以提高查询效率。
通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。

增加冗余字段
设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。
表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。

注意：冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。

MySQL数据库服务器CPU高占用，应该从那些方面进行分析？
使用top命令查看是否是MySQL高占用CPU；
show processlist，查看 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成；
判断数据库连接是否激增，来判断是否遇到了流量洪峰。
如何对大表进行优化？
单表不拆分下的优化

限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。；
读/写分离： 经典的数据库拆分方案，主库负责写，从库负责读；
缓存： 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存；
分库分表

垂直拆分：
根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示：

c1	c2	c3	c4	c5	c6	c7	c8	c9	c10
拆分为：

c1	c2	c3	c4
c1	c5	c6	c7	c8	c9	c10
垂直拆分的优点
行数据变小；
减少读取的Block数；
减少I/O次数；
简化表的结构；
易于维护。
垂直拆分的缺点
主键会出现冗余；
需要管理冗余列；
会引起Join操作；
让事务变得更加复杂。
水平拆分
保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。

水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。如下示例：
200W数据

c1	c2	c3	c4	c5	c6	c7	c8	c9	c10
拆分为两个100W
100W表A

c1	c2	c3	c4	c5	c6	c7	c8	c9	c10
100W表B

c1	c2	c3	c4	c5	c6	c7	c8	c9	c10
水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。

分库分表后将面临那些棘手的问题？
事务支持
分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。

跨库join
只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 分库分表方案产品

跨节点的count,order by,group by以及聚合函数问题
这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。

数据迁移，容量规划，扩容等问题
来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。

ID问题
一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由.

常见的主键生成策略
UUID
使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。
Twitter的分布式自增ID算法Snowflake
在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。
跨分片的排序分页
一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：

MySQL的复制原理以及流程是什么？
主从复制：
将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。

主从复制的作用

主数据库出现问题，可以切换到从数据库。
可以进行数据库层面的读写分离。
可以在从数据库上进行日常备份。
MySQL主从复制解决的问题

数据分布：
随意开始或停止复制，并在不同地理位置分布数据备份
负载均衡：
降低单个服务器的压力
高可用和故障切换：
帮助应用程序避免单点失败
升级测试：
可以用更高版本的MySQL作为从库
MySQL主从复制工作原理

在主库上把数据更高记录到二进制日志
从库将主库的日志复制到自己的中继日志
从库读取中继日志的事件，将其重放到从库数据中
基本原理流程，3个线程以及之间的关联

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；

从：sql执行线程——执行relay log中的语句；

复制过程


Binary log：主数据库的二进制日志
Relay log：从服务器的中继日志

第一步：
master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

第二步：
salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

第三步：
SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。


https://lupengfei.blog.csdn.net/article/details/113405031#t10